{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"/home/graham/Documents/Ironhack/Final-Project\")\n",
    "import src\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ('/home/graham/Documents/Ironhack/Final-Project/data/combined_data.csv')\n",
    "df = src.read_csv_file(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['2021 TR', '2022 TR', '2021 Inf', '2021 ED', '2022 ED', '2021 GHI', '2022 GHI']]\n",
    "y = df['2022 Inf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'regressor__max_depth': 5, 'regressor__max_features': 'sqrt', 'regressor__min_samples_leaf': 1, 'regressor__min_samples_split': 5}\n",
      "Best score: -0.2551617791254649\n",
      "Decision Tree R^2 score: -0.5942452712475599\n"
     ]
    }
   ],
   "source": [
    "'''DECISION TREE'''\n",
    "X = df[['2021 TR', '2022 TR', '2021 Inf', '2021 ED', '2022 ED', '2021 GHI', '2022 GHI']]\n",
    "y = df['2022 Inf']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create pipeline with DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "pipeline = Pipeline(steps=[('regressor', tree_reg)])\n",
    "\n",
    "# Define hyperparameters for grid search\n",
    "parameters = {'regressor__max_depth': [3, 5, 7, 10],\n",
    "              'regressor__min_samples_split': [2, 5, 10],\n",
    "              'regressor__min_samples_leaf': [1, 2, 4],\n",
    "              'regressor__max_features': ['sqrt', 'log2', None]}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, scoring='r2')\n",
    "\n",
    "# Fit GridSearchCV object to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best hyperparameters and score\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "# Use best model to predict on test data\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate performance of best model\n",
    "r2_score = r2_score(y_test, y_pred)\n",
    "print(\"Decision Tree R^2 score:\", r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''LINEAR REGRESSION'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[['2021 TR', '2022 TR','2021 Inf', '2021 ED', '2022 ED', '2021 GHI', '2022 GHI', ]],\n",
    "    df['2022 Inf'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "lr = LinearRegression()\n",
    "\n",
    "pipeline = Pipeline([('scaler', scaler), ('lr', lr)])\n",
    "\n",
    "param_grid = {\n",
    "    'lr__fit_intercept': [True, False],\n",
    "    'lr__copy_X': [True, False]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m r2 \u001b[39m=\u001b[39m r2_score(y_test, y_pred)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLinear Regression R^2 score:\u001b[39m\u001b[39m\"\u001b[39m, r2)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest parameters:\u001b[39m\u001b[39m\"\u001b[39m, grid\u001b[39m.\u001b[39mbest_params_)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Linear Regression R^2 score:\", r2)\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.99728599, 10.07603279, 14.17581369, 15.54562451, 15.64162182,\n",
       "       16.53508682, 14.94827293])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "H2OValueError",
     "evalue": "dtype is only supported for one column frames",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mH2OValueError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39m# Scale the feature variables\u001b[39;00m\n\u001b[1;32m      7\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[0;32m----> 8\u001b[0m X_scaled \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mfit_transform(X)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Split data into training and testing sets\u001b[39;00m\n\u001b[1;32m     11\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X_scaled, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/streamlit/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/streamlit/lib/python3.10/site-packages/sklearn/base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/envs/streamlit/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:824\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 824\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[0;32m~/anaconda3/envs/streamlit/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:861\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m    860\u001b[0m first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 861\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    862\u001b[0m     X,\n\u001b[1;32m    863\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    864\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m    865\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    866\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_call,\n\u001b[1;32m    867\u001b[0m )\n\u001b[1;32m    868\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m    870\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/streamlit/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/anaconda3/envs/streamlit/lib/python3.10/site-packages/sklearn/utils/validation.py:752\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[39m# store whether originally we wanted numeric dtype\u001b[39;00m\n\u001b[1;32m    750\u001b[0m dtype_numeric \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(dtype, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m dtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 752\u001b[0m dtype_orig \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(array, \u001b[39m\"\u001b[39;49m\u001b[39mdtype\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    753\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(dtype_orig, \u001b[39m\"\u001b[39m\u001b[39mkind\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    754\u001b[0m     \u001b[39m# not a data type (e.g. a column named dtype in a pandas DataFrame)\u001b[39;00m\n\u001b[1;32m    755\u001b[0m     dtype_orig \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/streamlit/lib/python3.10/site-packages/h2o/frame.py:379\u001b[0m, in \u001b[0;36mH2OFrame.dtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[39mReturns the numpy.dtype of the first column of this data frame.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[39mWorks only for single-column data frames.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39m:returns: Numpy dtype of the first column\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     \u001b[39mraise\u001b[39;00m H2OValueError(\u001b[39m\"\u001b[39m\u001b[39mdtype is only supported for one column frames\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m can_use_numpy():\n\u001b[1;32m    381\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mH2OFrame.dtype function requires numpy to be installed\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mH2OValueError\u001b[0m: dtype is only supported for one column frames"
     ]
    }
   ],
   "source": [
    "\n",
    "'''Random Forest'''\n",
    "# Define feature and target variables\n",
    "X = df[['2021 TR', '2022 TR', '2021 Inf', '2021 ED', '2022 ED', '2021 GHI', '2022 GHI']]\n",
    "y = df['2022 Inf']\n",
    "\n",
    "# Scale the feature variables\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [3, 5, 7, None]\n",
    "}\n",
    "\n",
    "# Define random forest regressor\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "rf_grid = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Print best hyperparameters and score\n",
    "print(\"Best parameters:\", rf_grid.best_params_)\n",
    "print(\"Best score:\", rf_grid.best_score_)\n",
    "\n",
    "# Predict on test set with best model from grid search\n",
    "y_pred = rf_grid.predict(X_test)\n",
    "\n",
    "# Evaluate model performance on test set\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Random Forest R^2 score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
